# Cross-Platform Memory for Ollama: GitHub Sync Guide

## Overview

This guide will help you create a persistent memory system for your Ollama AI agent that syncs across your Android device and desktop PC using a private GitHub repository. Your AI will remember conversations, preferences, and context across all your devices.

## What You'll Achieve

- üìù **Persistent Memory**: AI remembers past conversations
- üîÑ **Cross-Device Sync**: Access the same AI memory on Android and PC
- üîí **Private & Secure**: Uses private GitHub repository
- üíæ **Version Control**: Track memory changes over time
- üåê **Automatic Backup**: Your AI's memory is safely stored in the cloud

---

## Prerequisites

### On Desktop PC:
- ‚úÖ Git installed
- ‚úÖ GitHub account created
- ‚úÖ Ollama installed (optional, for testing)

### On Android:
- ‚úÖ Termux installed (from F-Droid)
- ‚úÖ Ubuntu via proot-distro
- ‚úÖ Ollama installed and working

---

## Part 1: Setting Up GitHub Repository (Desktop PC)

### Step 1: Create a GitHub Account

If you don't have one already:
1. Go to https://github.com
2. Click "Sign up"
3. Follow the registration process

### Step 2: Create a Private Repository

1. Log in to GitHub
2. Click the **"+"** icon (top right) ‚Üí **"New repository"**
3. Fill in the details:
   - **Repository name**: `ollama-memory`
   - **Description**: "Private memory storage for Ollama AI agent"
   - **Visibility**: Select **"Private"** (important!)
   - ‚úÖ Check **"Add a README file"**
   - ‚úÖ Check **"Add .gitignore"** ‚Üí Choose "Python"
4. Click **"Create repository"**

### Step 3: Set Up Repository Structure

Open terminal/command prompt on your desktop and run:

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/ollama-memory.git
cd ollama-memory

# Create directory structure
mkdir -p memory/{conversations,context,preferences}
```

### Step 4: Create Memory Template Files

Create a file `memory/context/system_context.txt`:
```bash
nano memory/context/system_context.txt
```

Add initial content:
```
System Context for Ollama Agent
================================
Created: [DATE]
Last Updated: [DATE]

User Preferences:
- Communication style: [To be learned]
- Preferred topics: [To be learned]

Known Information:
- [Information will be added over time]
```

Create a file `memory/preferences/user_profile.json`:
```bash
nano memory/preferences/user_profile.json
```

Add:
```json
{
  "version": "1.0",
  "user_name": "",
  "timezone": "",
  "interests": [],
  "communication_style": "",
  "important_dates": {},
  "notes": []
}
```

Create a file `memory/conversations/conversation_log.jsonl`:
```bash
touch memory/conversations/conversation_log.jsonl
```

### Step 5: Create Memory Management Script

Create `update_memory.py`:
```bash
nano update_memory.py
```

Add this code:
```python
#!/usr/bin/env python3
"""
Ollama Memory Manager
Handles reading and writing AI memory across devices
"""

import json
import os
from datetime import datetime
from pathlib import Path

MEMORY_DIR = Path("memory")
CONVERSATIONS_DIR = MEMORY_DIR / "conversations"
CONTEXT_FILE = MEMORY_DIR / "context" / "system_context.txt"
PROFILE_FILE = MEMORY_DIR / "preferences" / "user_profile.json"
CONVERSATION_LOG = CONVERSATIONS_DIR / "conversation_log.jsonl"

class MemoryManager:
    def __init__(self):
        self.ensure_directories()
    
    def ensure_directories(self):
        """Create directories if they don't exist"""
        MEMORY_DIR.mkdir(exist_ok=True)
        CONVERSATIONS_DIR.mkdir(exist_ok=True)
        (MEMORY_DIR / "context").mkdir(exist_ok=True)
        (MEMORY_DIR / "preferences").mkdir(exist_ok=True)
    
    def load_context(self):
        """Load system context"""
        if CONTEXT_FILE.exists():
            return CONTEXT_FILE.read_text()
        return ""
    
    def save_context(self, context):
        """Save system context"""
        CONTEXT_FILE.write_text(context)
    
    def load_profile(self):
        """Load user profile"""
        if PROFILE_FILE.exists():
            with open(PROFILE_FILE, 'r') as f:
                return json.load(f)
        return {}
    
    def save_profile(self, profile):
        """Save user profile"""
        with open(PROFILE_FILE, 'w') as f:
            json.dump(profile, f, indent=2)
    
    def add_conversation(self, user_input, ai_response):
        """Log a conversation exchange"""
        entry = {
            "timestamp": datetime.now().isoformat(),
            "user": user_input,
            "assistant": ai_response
        }
        
        with open(CONVERSATION_LOG, 'a') as f:
            f.write(json.dumps(entry) + '\n')
    
    def get_recent_conversations(self, limit=10):
        """Retrieve recent conversations"""
        if not CONVERSATION_LOG.exists():
            return []
        
        conversations = []
        with open(CONVERSATION_LOG, 'r') as f:
            for line in f:
                try:
                    conversations.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
        
        return conversations[-limit:]
    
    def build_prompt_context(self, user_query, include_history=True):
        """Build full context for Ollama prompt"""
        context_parts = []
        
        # Add system context
        system_context = self.load_context()
        if system_context:
            context_parts.append("=== System Context ===")
            context_parts.append(system_context)
        
        # Add user profile
        profile = self.load_profile()
        if profile:
            context_parts.append("\n=== User Profile ===")
            context_parts.append(json.dumps(profile, indent=2))
        
        # Add recent conversation history
        if include_history:
            recent = self.get_recent_conversations(5)
            if recent:
                context_parts.append("\n=== Recent Conversation History ===")
                for conv in recent:
                    context_parts.append(f"User: {conv['user']}")
                    context_parts.append(f"Assistant: {conv['assistant']}\n")
        
        # Add current query
        context_parts.append("\n=== Current Query ===")
        context_parts.append(f"User: {user_query}")
        context_parts.append("\nAssistant:")
        
        return "\n".join(context_parts)
    
    def update_context_with_learning(self, new_info):
        """Add learned information to context"""
        context = self.load_context()
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
        context += f"\n[{timestamp}] {new_info}"
        self.save_context(context)

if __name__ == "__main__":
    # Test the memory manager
    manager = MemoryManager()
    print("Memory Manager initialized successfully!")
    print(f"Memory directory: {MEMORY_DIR.absolute()}")
```

Make it executable:
```bash
chmod +x update_memory.py
```

### Step 6: Create README

Create `README.md`:
```bash
nano README.md
```

Add:
```markdown
# Ollama Memory Repository

Private memory storage for cross-platform Ollama AI agent.

## Structure

- `memory/conversations/` - Conversation history logs
- `memory/context/` - System context and learned information  
- `memory/preferences/` - User preferences and profile
- `update_memory.py` - Memory management script
- `ollama_with_memory.py` - Chat interface with memory

## Usage

### Pull latest memory
```bash
git pull
```

### Push memory updates
```bash
git add .
git commit -m "Update memory: [description]"
git push
```

## Never Share This Repository

This repository contains private conversation data. Keep it private!
```

### Step 7: Initial Commit and Push

```bash
# Add all files
git add .

# Commit
git commit -m "Initial memory structure"

# Push to GitHub
git push origin main
```

Your memory repository is now set up on GitHub!

---

## Part 2: Generate GitHub Personal Access Token

GitHub requires a Personal Access Token (PAT) for authentication from command line.

### Step 1: Create Token

1. Go to GitHub.com and log in
2. Click your profile picture (top right) ‚Üí **Settings**
3. Scroll down to **Developer settings** (left sidebar, near bottom)
4. Click **Personal access tokens** ‚Üí **Tokens (classic)**
5. Click **"Generate new token"** ‚Üí **"Generate new token (classic)"**
6. Fill in:
   - **Note**: "Ollama Memory Sync - Android & Desktop"
   - **Expiration**: 90 days (or longer)
   - **Scopes**: Check ‚úÖ **repo** (this gives full control of private repositories)
7. Click **"Generate token"**

### Step 2: Save Your Token

‚ö†Ô∏è **CRITICAL**: Copy the token immediately! You won't be able to see it again.

**Save it somewhere secure** - you'll need it for both Android and Desktop.

Example token format:
```
ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

---

## Part 3: Configure Git on Desktop PC

### Step 1: Configure Git Identity

```bash
git config --global user.name "Your Name"
git config --global user.email "your.email@example.com"
```

### Step 2: Cache Credentials

Linux/Mac:
```bash
git config --global credential.helper cache
git config --global credential.helper 'cache --timeout=31536000'
```

Windows:
```bash
git config --global credential.helper wincred
```

### Step 3: Test Authentication

```bash
cd ~/ollama-memory  # or wherever you cloned it
git pull
```

Enter your GitHub username and use the **Personal Access Token** as the password.

---

## Part 4: Set Up Git on Android (Termux)

### Step 1: Access Ubuntu Environment

Open Termux:
```bash
proot-distro login ubuntu
```

### Step 2: Install Git

```bash
apt update
apt install -y git
```

### Step 3: Configure Git Identity

```bash
git config --global user.name "Your Name"
git config --global user.email "your.email@example.com"
```

### Step 4: Set Up Credential Helper

```bash
# Use store helper to save credentials permanently
git config --global credential.helper store
```

‚ö†Ô∏è **Security Note**: This stores your token in plain text at `~/.git-credentials`. Since your Android device should be encrypted and protected, this is acceptable for personal use.

### Step 5: Clone Repository

```bash
cd ~
git clone https://github.com/YOUR_USERNAME/ollama-memory.git
```

When prompted:
- **Username**: Your GitHub username
- **Password**: Paste your Personal Access Token (the `ghp_xxx...` token)

The credentials will be saved for future use.

### Step 6: Verify Setup

```bash
cd ollama-memory
git pull
```

Should work without asking for credentials!

---

## Part 5: Create Memory-Enabled Chat Script (Android)

### Step 1: Navigate to Memory Directory

```bash
cd ~/ollama-memory
```

### Step 2: Create Chat Script with Memory

Create `ollama_with_memory.py`:
```bash
nano ollama_with_memory.py
```

Add this code:
```python
#!/usr/bin/env python3
"""
Ollama Chat with Persistent Memory
Syncs memory across devices via GitHub
"""

import json
import requests
import subprocess
import sys
from datetime import datetime
from pathlib import Path

# Configuration
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "phi"  # Change to your model
MEMORY_DIR = Path("memory")
CONVERSATIONS_DIR = MEMORY_DIR / "conversations"
CONTEXT_FILE = MEMORY_DIR / "context" / "system_context.txt"
PROFILE_FILE = MEMORY_DIR / "preferences" / "user_profile.json"
CONVERSATION_LOG = CONVERSATIONS_DIR / "conversation_log.jsonl"

class MemoryManager:
    def __init__(self):
        self.ensure_directories()
    
    def ensure_directories(self):
        """Create directories if they don't exist"""
        MEMORY_DIR.mkdir(exist_ok=True)
        CONVERSATIONS_DIR.mkdir(exist_ok=True)
        (MEMORY_DIR / "context").mkdir(exist_ok=True)
        (MEMORY_DIR / "preferences").mkdir(exist_ok=True)
    
    def load_context(self):
        """Load system context"""
        if CONTEXT_FILE.exists():
            return CONTEXT_FILE.read_text()
        return ""
    
    def save_context(self, context):
        """Save system context"""
        CONTEXT_FILE.write_text(context)
    
    def load_profile(self):
        """Load user profile"""
        if PROFILE_FILE.exists():
            with open(PROFILE_FILE, 'r') as f:
                return json.load(f)
        return {}
    
    def save_profile(self, profile):
        """Save user profile"""
        with open(PROFILE_FILE, 'w') as f:
            json.dump(profile, f, indent=2)
    
    def add_conversation(self, user_input, ai_response):
        """Log a conversation exchange"""
        entry = {
            "timestamp": datetime.now().isoformat(),
            "user": user_input,
            "assistant": ai_response
        }
        
        with open(CONVERSATION_LOG, 'a') as f:
            f.write(json.dumps(entry) + '\n')
    
    def get_recent_conversations(self, limit=5):
        """Retrieve recent conversations"""
        if not CONVERSATION_LOG.exists():
            return []
        
        conversations = []
        with open(CONVERSATION_LOG, 'r') as f:
            for line in f:
                try:
                    conversations.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
        
        return conversations[-limit:]
    
    def build_prompt_context(self, user_query):
        """Build full context for Ollama prompt"""
        context_parts = []
        
        # Add system context
        system_context = self.load_context()
        if system_context.strip():
            context_parts.append("Previous context and learned information:")
            context_parts.append(system_context)
            context_parts.append("")
        
        # Add recent conversation history
        recent = self.get_recent_conversations(3)
        if recent:
            context_parts.append("Recent conversation history:")
            for conv in recent:
                context_parts.append(f"User: {conv['user']}")
                context_parts.append(f"Assistant: {conv['assistant']}")
            context_parts.append("")
        
        # Add current query
        context_parts.append(f"User: {user_query}")
        
        return "\n".join(context_parts)

def git_sync(operation="pull"):
    """Sync memory with GitHub"""
    try:
        if operation == "pull":
            print("üì• Pulling latest memory from GitHub...")
            result = subprocess.run(
                ["git", "pull"],
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                print("‚úì Memory synced from GitHub")
            else:
                print(f"‚ö†Ô∏è  Pull warning: {result.stderr}")
        
        elif operation == "push":
            print("üì§ Pushing memory to GitHub...")
            
            # Add all changes
            subprocess.run(["git", "add", "."])
            
            # Commit with timestamp
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            commit_msg = f"Memory update: {timestamp}"
            subprocess.run(["git", "commit", "-m", commit_msg])
            
            # Push
            result = subprocess.run(
                ["git", "push"],
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                print("‚úì Memory backed up to GitHub")
            else:
                print(f"‚ö†Ô∏è  Push warning: {result.stderr}")
    
    except Exception as e:
        print(f"‚ö†Ô∏è  Git sync error: {e}")

def ask_ollama(prompt):
    """Send prompt to Ollama and get response"""
    try:
        payload = {
            "model": MODEL_NAME,
            "prompt": prompt,
            "stream": False
        }
        
        response = requests.post(OLLAMA_URL, json=payload, timeout=120)
        
        if response.status_code == 200:
            result = response.json()
            return result.get('response', 'No response generated.')
        else:
            return f"Error: Status code {response.status_code}"
    
    except requests.exceptions.ConnectionError:
        return "Error: Cannot connect to Ollama. Is it running?"
    except Exception as e:
        return f"Error: {str(e)}"

def main():
    """Main chat loop with memory"""
    print("=" * 60)
    print("  OLLAMA CHAT WITH PERSISTENT MEMORY")
    print("=" * 60)
    print(f"Model: {MODEL_NAME}")
    print(f"Memory location: {MEMORY_DIR.absolute()}")
    print("\nCommands:")
    print("  /sync      - Pull latest memory from GitHub")
    print("  /backup    - Push current memory to GitHub")
    print("  /clear     - Clear conversation history")
    print("  /context   - Show current context")
    print("  /quit      - Exit (auto-backup)")
    print("=" * 60)
    
    # Initialize memory manager
    memory = MemoryManager()
    
    # Sync memory from GitHub at startup
    git_sync("pull")
    
    print("\n‚úì Ready to chat!\n")
    
    try:
        while True:
            # Get user input
            user_input = input("You: ").strip()
            
            if not user_input:
                continue
            
            # Handle commands
            if user_input == "/quit":
                print("\nBacking up memory before exit...")
                git_sync("push")
                print("Goodbye! üëã")
                break
            
            elif user_input == "/sync":
                git_sync("pull")
                continue
            
            elif user_input == "/backup":
                git_sync("push")
                continue
            
            elif user_input == "/clear":
                if CONVERSATION_LOG.exists():
                    CONVERSATION_LOG.unlink()
                print("‚úì Conversation history cleared")
                continue
            
            elif user_input == "/context":
                context = memory.load_context()
                if context:
                    print("\n--- Current Context ---")
                    print(context)
                    print("--- End Context ---\n")
                else:
                    print("No context stored yet.")
                continue
            
            # Build prompt with memory context
            full_prompt = memory.build_prompt_context(user_input)
            
            # Get response from Ollama
            print("\nü§î Thinking...\n")
            response = ask_ollama(full_prompt)
            
            # Display response
            print(f"AI: {response}\n")
            
            # Save to memory
            memory.add_conversation(user_input, response)
            
            # Auto-backup every 5 conversations
            conversation_count = len(memory.get_recent_conversations(100))
            if conversation_count % 5 == 0:
                git_sync("push")
    
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interrupted. Backing up memory...")
        git_sync("push")
        print("Goodbye! üëã")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        git_sync("push")  # Try to backup even on error

if __name__ == "__main__":
    main()
```

Make it executable:
```bash
chmod +x ollama_with_memory.py
```

---

## Part 6: Using the Memory System

### On Android (Termux)

```bash
# Login to Ubuntu
proot-distro login ubuntu

# Start Ollama (if not running)
ollama serve &

# Navigate to memory directory
cd ~/ollama-memory

# Pull latest memory
git pull

# Start chat with memory
python3 ollama_with_memory.py
```

### On Desktop PC

```bash
# Navigate to memory directory
cd ~/ollama-memory

# Pull latest memory
git pull

# Start chat with memory
python3 ollama_with_memory.py
```

### Workflow

1. **Before chatting**: Run `git pull` to get latest memory
2. **During chat**: Use `/backup` command to save memory
3. **After chatting**: Script auto-backs up on exit
4. **Switch devices**: Pull on new device to continue where you left off

---

## Part 7: Memory Management Commands

### In-Chat Commands

While running `ollama_with_memory.py`:

- `/sync` - Pull latest memory from GitHub
- `/backup` - Push current memory to GitHub
- `/clear` - Clear conversation history (use carefully!)
- `/context` - View current system context
- `/quit` - Exit and auto-backup

### Manual Git Commands

```bash
# Pull latest memory
git pull

# View status
git status

# Manual commit and push
git add .
git commit -m "Updated memory on [device name]"
git push

# View commit history
git log --oneline

# View changes
git diff
```

---

## Part 8: Advanced Memory Features

### Adding Permanent Context

To add permanent information the AI should remember:

```bash
nano memory/context/system_context.txt
```

Add information like:
```
User Information:
- Name: John
- Location: New York
- Occupation: Software Developer
- Interests: Python, AI, robotics

Important Facts:
- User prefers detailed technical explanations
- Working on a machine learning project
- Uses both Android and desktop for development
```

Then commit and push:
```bash
git add memory/context/system_context.txt
git commit -m "Updated system context"
git push
```

### Reviewing Conversation History

```bash
# View recent conversations
cat memory/conversations/conversation_log.jsonl | tail -n 20

# Search conversations
grep "keyword" memory/conversations/conversation_log.jsonl

# Count conversations
wc -l memory/conversations/conversation_log.jsonl
```

### Creating Conversation Summaries

Create `summarize_memory.py`:
```python
#!/usr/bin/env python3
import json
from pathlib import Path

CONVERSATION_LOG = Path("memory/conversations/conversation_log.jsonl")

conversations = []
with open(CONVERSATION_LOG, 'r') as f:
    for line in f:
        conversations.append(json.loads(line))

print(f"Total conversations: {len(conversations)}")
print(f"Date range: {conversations[0]['timestamp']} to {conversations[-1]['timestamp']}")
print("\nRecent topics:")
for conv in conversations[-10:]:
    print(f"- {conv['user'][:60]}...")
```

---

## Part 9: Troubleshooting

### Authentication Issues

**Problem:** Git asks for password every time

**Solutions:**

Android:
```bash
git config --global credential.helper store
```

Desktop (Linux/Mac):
```bash
git config --global credential.helper cache
git config --global credential.helper 'cache --timeout=31536000'
```

Desktop (Windows):
```bash
git config --global credential.helper wincred
```

### Merge Conflicts

**Problem:** "Your branch and 'origin/main' have diverged"

**Solutions:**

Option 1 - Accept remote version:
```bash
git fetch origin
git reset --hard origin/main
```

Option 2 - Keep local version:
```bash
git push --force
```

Option 3 - Merge manually:
```bash
git pull
# Edit conflicting files
git add .
git commit -m "Resolved merge conflict"
git push
```

### Token Expired

**Problem:** Authentication fails after token expires

**Solution:**
1. Generate new Personal Access Token on GitHub
2. Remove old credentials:
   ```bash
   rm ~/.git-credentials
   ```
3. Next `git pull` will ask for new credentials

### Connection Issues

**Problem:** "Failed to connect to github.com"

**Solutions:**
1. Check internet connection
2. Try: `ping github.com`
3. Check if GitHub is down: https://www.githubstatus.com/
4. Verify repository URL: `git remote -v`

### Large Repository Size

**Problem:** Repository getting too large

**Solutions:**

Clean old conversations (keep last 100):
```python
# Create cleanup_old_conversations.py
import json
from pathlib import Path

log_file = Path("memory/conversations/conversation_log.jsonl")
conversations = []

with open(log_file, 'r') as f:
    for line in f:
        conversations.append(json.loads(line))

# Keep only last 100
recent = conversations[-100:]

with open(log_file, 'w') as f:
    for conv in recent:
        f.write(json.dumps(conv) + '\n')

print(f"Kept {len(recent)} conversations, removed {len(conversations) - len(recent)}")
```

---

## Part 10: Security Best Practices

### ‚úÖ DO:
- Keep repository **private**
- Use **Personal Access Token** (never password)
- Set token expiration (90-365 days)
- Use encrypted storage on mobile devices
- Regularly backup your memory repository
- Review commit history periodically

### ‚ùå DON'T:
- Share your Personal Access Token
- Make repository public
- Store sensitive passwords in memory files
- Commit API keys or secrets
- Share the repository URL publicly

### Additional Security

Add `.gitignore` to exclude sensitive files:
```bash
nano .gitignore
```

Add:
```
# Sensitive files
secrets.txt
api_keys.txt
*.env
.env

# Large temporary files
*.tmp
*.log
```

---

## Part 11: Backup and Recovery

### Create Full Backup

```bash
# Zip entire memory
cd ~
tar -czf ollama-memory-backup-$(date +%Y%m%d).tar.gz ollama-memory/

# Or just memory directory
cd ollama-memory
tar -czf ../memory-backup-$(date +%Y%m%d).tar.gz memory/
```

### Restore from Backup

```bash
# Extract backup
tar -xzf ollama-memory-backup-YYYYMMDD.tar.gz

# Or clone fresh from GitHub
git clone https://github.com/YOUR_USERNAME/ollama-memory.git
```

### Export Conversations

```python
# Create export_conversations.py
import json
from pathlib import Path
from datetime import datetime

log_file = Path("memory/conversations/conversation_log.jsonl")
output_file = f"conversations_export_{datetime.now().strftime('%Y%m%d')}.txt"

with open(log_file, 'r') as f:
    with open(output_file, 'w') as out:
        for line in f:
            conv = json.loads(line)
            out.write(f"\n{'='*60}\n")
            out.write(f"Time: {conv['timestamp']}\n")
            out.write(f"User: {conv['user']}\n")
            out.write(f"AI: {conv['assistant']}\n")

print(f"Exported to {output_file}")
```

---

## Part 12: Performance Optimization

### Limit Conversation History

In `ollama_with_memory.py`, adjust:
```python
def get_recent_conversations(self, limit=5):  # Reduce from 5 to 3
```

### Compress Old Logs

```bash
# Archive conversations older than 30 days
cd memory/conversations
gzip conversation_log_old.jsonl
```

### Use Shallow Clone (Faster)

```bash
# Clone only recent history
git clone --depth 1 https://github.com/YOUR_USERNAME/ollama-memory.git
```

---

## Part 13: Automation Scripts

### Auto-sync on Boot (Android)

Create `~/auto_sync.sh`:
```bash
#!/bin/bash
cd ~/ollama-memory
git pull
```

Make executable:
```bash
chmod +x ~/auto_sync.sh
```

Add to Termux boot script (if using Termux:Boot app).

### Scheduled Backup (Cron)

On desktop, add to crontab:
```bash
crontab -e
```

Add:
```
# Backup memory every 6 hours
0 */6 * * * cd ~/ollama-memory && git add . && git commit -m "Auto backup" && git push
```

---

## Conclusion

You now have a complete cross-platform memory system for your Ollama AI agent! Your AI can:

‚úÖ Remember conversations across devices  
‚úÖ Maintain context and learned information  
‚úÖ Sync automatically via GitHub  
‚úÖ Preserve memory even if devices are lost  
‚úÖ Track conversation history over time  

**Key Points to Remember:**
- Always `git pull` before starting conversations
- Memory auto-backs up every 5 conversations
- Use `/backup` command for manual saves
- Review memory periodically to keep it relevant
- Keep your GitHub token secure and private

Enjoy your AI assistant with perfect memory across all your devices! üß†‚ú®